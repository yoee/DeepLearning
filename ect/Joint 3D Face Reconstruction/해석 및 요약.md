# 논문 요약



## 3.3 Training Details

#### (1문단 : training 과정과 data의 변화)

- 300W-LP를 data set으로 채용했다!
  - 여기서 LP는 large pose의 약자로, 사진을 보면 하나의 2D 이미지에서 합성된 다양한 각도의 사진을 확인해볼 수 있다.
  - 다양한 이미지가 합성될 수 있었던 것은 3DMM coefficient의 지표를 활용해서 가능했던 것인데
    - 3D point cloud는 3DMM coefficient를 통하여 쉽게 생성되어질 수 있다.
- 특별히, ground truth bounding box를 통해서 256*256으로 사진을 잘랐다.
  - ground truth (추론에 의한 것이 아닌, 직접적인 관찰에 의하여 얻은 정보)
- 그리고 잘린 사진의 annotated 3DMM parameters를 활용해서 3D position을 구해냈다.
- 이후, ground truth position map을 얻기 위하여 uv map으로 이를 렌더링 했다.
  - 여기서의 map size 또한 256*256 
  - 이 말은, 우리가 regress해야하는 45K이상의 point cloud가 있다는 말이다. (❓256*256 = 65,536이라서 그런걸까)
- 비록 우리의 trainind data는 3DMM으로부터 만들어졌지만, 우리의 네트워크의 결과물인 position map은 그 어떤 face template이나 3DMM의 linear space에 구애받지 않는다! (❓어떻게)

#### (2문단 : data set 전처리와 training parameters)

- 학습 data 처리
  - 단순한 처리들
    - randomly rotating (-45도~45도)
    - input size 변동 (10%)
    - scale 조정 (0.9~1.2)
  - Augumentation
    - scaling color
    - noise (occulsion 해결을 위하여)
- training parameters
  - Adam optimizer
    - learning rate 0.0001
    - 5 epochs 이후에 half decay
    - batch size 16