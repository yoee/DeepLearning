# 이해한 것, 궁금한 것

</br>

## How to generate figures from own images?

### generate_figures.py

``` python
# url = (.pkl 형식)
def load_Gs(url):
    if url not in _Gs_cache:
        with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:
            _G, _D, Gs = pickle.load(f)
        _Gs_cache[url] = Gs
    return _Gs_cache[url]
```

Gs는 설명하기로는, `Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.` 그러니까, generator들의 평균 값으로 생산해내는 generator.

그리고 pre_trained Gs를 google drive url로 부터 불러오는데, 이 때의 형식은 `.pkl`이다. (pickle은 일반적인 텍스트가 아닌 다양한 자료형을 파일 입출력시 저장할 수 있게 해주는 모듈.)

그리고 아래는 함수 호출부와 함수

```Python
draw_uncurated_result_figure(os.path.join(config.result_dir, 'figure02-uncurated-ffhq.png'), load_Gs(url_ffhq), cx=0, cy=0, cw=1024, ch=1024, rows=3, lods=[0,1,2,2,3,3], seed=5)
```

```Python
'''
Args:
	png: 저장할 파일 이름
	Gs: averagate of generator
	cx, cy, cw, ch: image crop의 기준이 되는 값들
	rows: 행 개수
	lods: 하나 행과 열에 몇개의 사진이 들아갈지에 관한 값. 2의 지수로 쓰임.
	seed: 난수처럼 보이는 수를 만들기 위한 시작 숫자. 한번 seed 설정 -> 이후 rand 할 때 마다 같은 숫자 나옴.
'''
def draw_uncurated_result_figure(png, Gs, cx, cy, cw, ch, rows, lods, seed):
    print(png)
    # latent를 random하게 생성
    # Q. random을 주어도 항상 같은 output이 나오는 이유? A. RandomState는 항상 같은 random으로 보이는 값을 내려준다.
    latents = np.random.RandomState(seed).randn(sum(rows * 2**lod for lod in lods), Gs.input_shape[1])
    # Gs를 통하여 images를 생성.
    images = Gs.run(latents, None, **synthesis_kwargs) # [seed, y, x, rgb]

    # 알맞은 col과 lod에 맞추어 이미지 그려주기.
    canvas = PIL.Image.new('RGB', (sum(cw // 2**lod for lod in lods), ch * rows), 'white')
    image_iter = iter(list(images))
    for col, lod in enumerate(lods):
        for row in range(rows * 2**lod):
            image = PIL.Image.fromarray(next(image_iter), 'RGB')
            image = image.crop((cx, cy, cx + cw, cy + ch))
            image = image.resize((cw // 2**lod, ch // 2**lod), PIL.Image.ANTIALIAS)
            canvas.paste(image, (sum(cw // 2**lod for lod in lods[:col]), row * ch // 2**lod))
    canvas.save(png)
```

나의 image를 넣으려면, Gs.run이 생성하는 것과 같은 images를 만들어서 넣어주면 될 것 같다. Gs의 type을 찍어보니 `<class 'dnnlib.tflib.network.Network'>`. 여기서 run 함수를 살펴보자. 

[class Network의 run함수](<https://github.com/NVlabs/stylegan/blob/master/dnnlib/tflib/network.py>) 살펴 봤는데 어렵다.. 간단히 형식만 맞추어서 생성하기는 힘들 것 같다.

</br>

### own image -> StyleGAN latent space

~~StyleGAN의 latent space에 맞는 input image를 만들어 주어야 한다. 그리고, 관련 논문을 찾았다. [Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?](<https://www.researchgate.net/publication/332300501_Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space>)  ([블로그](<https://www.groundai.com/project/image2stylegan-how-to-embed-images-into-the-stylegan-latent-space/1>))~~

앗, 누가 우리의 이미지를 StyleGAN에 넣을 수 있는 Encoder를 만들어주었당. [그 분의 GitHub.](<https://github.com/Puzer/stylegan-encoder>) Generating latent representation of your images 부분을 보면 된다.

```Python
# 1) Extract and align faces from images
python align_images.py raw_images/ aligned_images/

# 2) Find latent representation of aligned images
python encode_images.py aligned_images/ generated_images/ latent_representations/
```

사용 예제는 [Play with latent direction.py](<https://github.com/Puzer/stylegan-encoder/blob/master/Play_with_latent_directions.ipynb>) 

